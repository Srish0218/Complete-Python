{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/ml-linear-regression/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1023b5cc63da18d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Linear regression \n",
    "is a simple and widely used statistical technique for modeling the relationship between a dependent variable (target) and one or more independent variables (features). The goal of linear regression is to find the best-fitting linear relationship that minimizes the sum of squared differences between the predicted and actual values of the dependent variable. The equation of a linear regression model is typically represented as:\n",
    "\n",
    "y=b 0​ +b1​⋅x 1​\n",
    " +b \n",
    "2\n",
    "​\n",
    " ⋅x \n",
    "2\n",
    "​\n",
    " +…+b \n",
    "n\n",
    "​\n",
    " ⋅x \n",
    "n\n",
    "​\n",
    "\n",
    "Here:\n",
    "- \\( y \\) is the dependent variable (target).\n",
    "- \\( b_0 \\) is the y-intercept (constant term).\n",
    "- \\( b_1, b_2, \\ldots, b_n \\) are the coefficients of the independent variables.\n",
    "- \\( x_1, x_2, \\ldots, x_n \\) are the independent variables.\n",
    "\n",
    "The goal during training is to find the values of \\( b_0, b_1, b_2, \\ldots, b_n \\) that minimize the residual sum of squares (RSS), which is the sum of the squared differences between the predicted and actual values.\n",
    "\n",
    "### Steps in Linear Regression:\n",
    "\n",
    "1. **Data Preparation:**\n",
    "   - Organize the dataset into feature variables (\\( x \\)) and the target variable (\\( y \\)).\n",
    "   - Split the dataset into training and testing sets.\n",
    "\n",
    "2. **Model Definition:**\n",
    "   - Define the linear regression model with the appropriate number of features.\n",
    "\n",
    "3. **Training:**\n",
    "   - Use the training data to find the optimal values for the coefficients (\\( b_0, b_1, b_2, \\ldots, b_n \\)) that minimize the RSS.\n",
    "\n",
    "4. **Prediction:**\n",
    "   - Use the trained model to make predictions on new or unseen data.\n",
    "\n",
    "### Example Using Python and Scikit-Learn:\n",
    "\n",
    "Here's a simple example of linear regression using the `LinearRegression` class from the scikit-learn library:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "X = 2 * np.random.rand(100, 1)\n",
    "y = 4 + 3 * X + np.random.randn(100, 1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Plot the data and the linear regression line\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this example, synthetic data is generated with a linear relationship. The linear regression model is trained on the training set, and predictions are made on the test set. The performance of the model is evaluated using mean squared error, and the results are visualized using a scatter plot and the linear regression line."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "37eada530623b6a4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Simple linear Regression: y = b0 + b1x\n",
    "Multiple                : y = b0 + b1x1 + b2x2 + ... + bnxn "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cddb177aef74d88"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assumption\n",
    "- linearity\n",
    "- independence\n",
    "- normality\n",
    "- homo\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "524c87ac1d690eb4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Assumptions of Simple Linear Regression\n",
    "Linear regression is a powerful tool for understanding and predicting the behavior of a variable, however, it needs to meet a few conditions in order to be accurate and dependable solutions. \n",
    "\n",
    "**Linearity**: The independent and dependent variables have a linear relationship with one another. This implies that changes in the dependent variable follow those in the independent variable(s) in a linear fashion. This means that there should be a straight line that can be drawn through the data points. If the relationship is not linear, then linear regression will not be an accurate model.\n",
    "\n",
    "**Independence**: The observations in the dataset are independent of each other. This means that the value of the dependent variable for one observation does not depend on the value of the dependent variable for another observation. If the observations are not independent, then linear regression will not be an accurate model.\n",
    "**Homoscedasticity**: Across all levels of the independent variable(s), the variance of the errors is constant. This indicates that the amount of the independent variable(s) has no impact on the variance of the errors. If the variance of the residuals is not constant, then linear regression will not be an accurate model.\n",
    "\n",
    "Homoscedasticity in Linear Regression\n",
    "\n",
    "Normality: The residuals should be normally distributed. This means that the residuals should follow a bell-shaped curve. If the residuals are not normally distributed, then linear regression will not be an accurate model."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14f623b686b3b171"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/how-to-calculate-mean-absolute-error-in-python/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29ddc70ef77466c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluating Lin Reg Model\n",
    "1. **Mean Absolute Error** -- sumision(actual - pred) / n\n",
    "2. **MEAN SQUARED ERROR**  -- sumision(actual - pred)**2 / n\n",
    "3. **Root Mean Squared Erro** -- SQRT[sumision(actual - pred)**2 / n]\n",
    "4. **Coefficient of Determination (R-squared)** - R**2 = 1 - [Residual sum of Squares (RSS)/Total Sum of Squares (TSS)]\n",
    "5. \n",
    "Residual sum of Squares (RSS) - _sumision(actual - pred)**2 / n_\n",
    "Total Sum of Squares (TSS) - _sumision(actual - MEAN)**2 / n_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba695da5be5b080a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7206077273177b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
