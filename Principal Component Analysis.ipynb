{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# https://www.geeksforgeeks.org/principal-component-analysis-pca/"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-14T12:17:25.793327700Z",
     "start_time": "2024-01-14T12:17:25.787603900Z"
    }
   },
   "id": "b623a7abc97f201b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "is a dimensionality reduction technique commonly used in machine learning and statistics. Its main objective is to transform high-dimensional data into a lower-dimensional representation, capturing as much variance as possible. PCA achieves this by identifying the principal components, which are the orthogonal directions in the feature space along which the data varies the most.\n",
    "\n",
    "### Steps in Principal Component Analysis (PCA):\n",
    "\n",
    "1. **Standardization:**\n",
    "   - Standardize the features (subtract the mean and divide by the standard deviation) to ensure that all features have the same scale.\n",
    "\n",
    "2. **Covariance Matrix Calculation:**\n",
    "   - Compute the covariance matrix of the standardized data. The covariance matrix provides information about the relationships between different features.\n",
    "\n",
    "3. **Eigendecomposition:**\n",
    "   - Perform eigendecomposition on the covariance matrix to obtain the eigenvalues and eigenvectors. Each eigenvector represents a principal component, and the corresponding eigenvalue represents the amount of variance explained by that component.\n",
    "\n",
    "4. **Sort Eigenvectors:**\n",
    "   - Sort the eigenvectors in descending order based on their corresponding eigenvalues. This allows you to prioritize the principal components that capture the most variance.\n",
    "\n",
    "5. **Select Principal Components:**\n",
    "   - Choose the top \\(k\\) eigenvectors (principal components) based on the desired dimensionality reduction. The cumulative explained variance can be used to determine the appropriate number of components.\n",
    "\n",
    "6. **Projection:**\n",
    "   - Project the original data onto the selected principal components to obtain the lower-dimensional representation.\n",
    "\n",
    "### Example Using Python and Scikit-Learn:\n",
    "\n",
    "Here's an example of applying PCA to a synthetic dataset using the `PCA` class from scikit-learn:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data with two features\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 2) * 10  # Two-dimensional data\n",
    "\n",
    "# Apply PCA with two components\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Visualize the original and transformed data\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X[:, 0], X[:, 1], alpha=0.8, s=50)\n",
    "plt.title('Original Data')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.8, s=50)\n",
    "plt.title('PCA Transformed Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "In this example, synthetic data with two features is generated. PCA is then applied to transform the data into a two-dimensional space. The scatter plots visualize the original data and the transformed data after applying PCA. The transformed data is represented along the principal components, capturing the most significant variations in the original data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9c64340d3585c17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Minimize projection residuals\n",
    "- Maximize Variance"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9c20f5a7709ecbc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1036c463bb4056e3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
